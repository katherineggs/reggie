{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "def accuracy(yTest, yPred):\n",
    "    \"\"\"\n",
    "    Classification accuracy is a ratio of the number of correct predictions out of all predictions that were made.\n",
    "    accuracy = TP+TN / FP+FN+TP+TN\n",
    "    \"\"\"\n",
    "    # -- OPCION 1 --\n",
    "    #TRUE positive\n",
    "    TP = sum((yTest == 1) & (yPred == 1))\n",
    "\n",
    "    #FALSE positive\n",
    "    FP = sum((yTest == 0) & (yPred == 1))\n",
    "\n",
    "    #FALSE positive\n",
    "    FN = sum((yTest == 1) & (yPred == 0))\n",
    "\n",
    "    #TRUE negative\n",
    "    TN = sum((yTest == 0) & (yPred == 0))\n",
    "    \n",
    "    return (TP + TN)/(FP + FN + TP + TN)\n",
    "\n",
    "    # -- OPCION 2 --\n",
    "    correct = 0\n",
    "    for i in range(len(yTest)):\n",
    "        if yTest[i] == yPred[i]:\n",
    "            correct += 1\n",
    "    # return correct / float(len(yTest)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy\n",
    "yTest = np.array([1,0,1,0,0,1,1,1,1,1])\n",
    "yPred = np.array([0,1,0,0,0,1,0,1,1,1])\n",
    "accuracy = accuracy(yTest, yPred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision\n",
    "def precision(yTest, yPred):\n",
    "    \"\"\"\n",
    "    Precision is the ratio between the true positives and all the points that are classified as positives.\n",
    "    precision = TP/(TP + FP)\n",
    "    \"\"\"\n",
    "\n",
    "    #TRUE positive\n",
    "    TP = sum((yTest == 1) & (yPred == 1))\n",
    "\n",
    "    #FALSE positive\n",
    "    FP = sum((yTest == 0) & (yPred == 1))\n",
    "\n",
    "    return TP / (TP + FP)\n",
    "\n",
    "    # -- OPCION 2 --\n",
    "    tp2 = 0\n",
    "    fp2 = 0\n",
    "    for i in range(len(yTest)):\n",
    "        if yTest[i] == yPred[i]:\n",
    "            tp2 += 1\n",
    "            \n",
    "        if yTest[i] != yPred[i]:\n",
    "            fp2 += 1\n",
    "    \n",
    "    # return float(tp2 / (tp2 + fp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n"
     ]
    }
   ],
   "source": [
    "# Test precision\n",
    "yTest = np.array([1,0,1,0,0,1,1,1,1,1])\n",
    "yPred = np.array([0,1,0,0,0,1,0,1,1,1])\n",
    "precision = precision(yTest, yPred)\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall\n",
    "def recall(yTest, yPred):\n",
    "    \"\"\"\n",
    "    Recall is the measure of the model correctly identifying true positives. \n",
    "    recall = TP/(TP + FN)\n",
    "    \"\"\"\n",
    "\n",
    "    #TRUE positive\n",
    "    TP = sum((yTest == 1) & (yPred == 1))\n",
    "\n",
    "    #FALSE negative\n",
    "    FN = sum((yTest == 1) & (yPred == 0))\n",
    "\n",
    "    return TP / float(TP + FN)\n",
    "\n",
    "    # -- OPCION 2 --\n",
    "    tp2 = 0\n",
    "    fn2 = 0\n",
    "    for i in range(len(yTest)):\n",
    "        if yTest[i] == yPred[i]:\n",
    "            tp2 += 1\n",
    "            \n",
    "        if yTest[i] != yPred[i]:\n",
    "            fn2 += 1\n",
    "    \n",
    "    # return float(tp2 / (tp2 + fn2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "# Test recall\n",
    "yTest = np.array([1,0,1,0,0,1,1,1,1,1])\n",
    "yPred = np.array([0,1,0,0,0,1,0,1,1,1])\n",
    "recall = recall(yTest, yPred)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 score\n",
    "def F1score(yTest, yPred):\n",
    "    \"\"\"\n",
    "    F1 score is the combination of precision and recall. \n",
    "    F1 score = (2 * precision * recall) / (precision + recall)\n",
    "    \"\"\"\n",
    "\n",
    "    Precision = precision(yTest, yPred)\n",
    "    Recall = recall(yTest, yPred)\n",
    "\n",
    "    return (2 * Precision * Recall) / (Precision + Recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Test F1score\n",
    "yTest = np.array([1,0,1,0,0,1,1,1,1,1])\n",
    "yPred = np.array([0,1,0,0,0,1,0,1,1,1])\n",
    "F1score = F1score(yTest, yPred)\n",
    "print(F1score)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "81f78be8e84c422d020e02bed99d970b4c01c3a614224aa9b2e56590be3a6b2a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
