{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(penalty='none', random_state=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "\n",
    "# import data\n",
    "iris = datasets.load_iris()\n",
    "df = pd.DataFrame(iris.data, columns = iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "\n",
    "X = df.iloc[:, [0,1,2, 3]].values\n",
    "y = df.iloc[:, 4].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "classifier = LogisticRegression(random_state = 0, solver='lbfgs', multi_class='auto', penalty=\"none\")\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLogisticReg():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def sigmoidFunc(self, z):\n",
    "        sigm = []\n",
    "        for i in range(len(z)):\n",
    "            lista = np.exp(z[i])/sum(np.exp(z[i]))\n",
    "            sigm.append(lista.tolist())\n",
    "        return sigm\n",
    "    \n",
    "    def getWeights(self,X,y):\n",
    "        cantTargs = len(np.unique(y))\n",
    "        feats = np.shape(X)[1] # columnas \n",
    "\n",
    "        self.weight = np.random.rand(feats, cantTargs) # array FEATURE * CLASES\n",
    "\n",
    "    def fit(self,X,y, rounds = 2, lRate=0.01):\n",
    "        \"\"\"\n",
    "        weighted sum of the inputs plus a bias term \n",
    "        For multiclass problems, only ‘newton-cg’, ‘sag’, ‘saga’ and ‘lbfgs’ \n",
    "        handle multinomial loss; SOFTMAX\n",
    "        \"\"\"\n",
    "        self.X = X #np.c_[np.ones((np.shape(X)[0],1)),X] # agregamos col de 1s\n",
    "        self.y = y\n",
    "        \n",
    "        self.getWeights(X,y)\n",
    "        weight = self.weight # a optimizar # random initialization of w a\n",
    "        \n",
    "        return \"hello\" #self.h\n",
    "    \n",
    "    def gradientDescent(self, rounds, weight, alpha, x, y):\n",
    "        for i in range(rounds):\n",
    "            z = np.dot(self.X, weight) # (w·x)\n",
    "            yG = self.sigmoidFunc(z) # yˆ = σ(w·x)\n",
    "\n",
    "            loss = self.lossFunction(yG, y) # loss entre ygorrito y y train\n",
    "\n",
    "            gradient = np.dot(self.X.T, loss)\n",
    "\n",
    "            #updtate a lo weights\n",
    "            weight -= alpha * gradient\n",
    "        \n",
    "        self.weight = weight\n",
    "        theta = \"θ\"\n",
    "        return theta\n",
    "\n",
    "    def lossFunction(self, y, yG):\n",
    "        \"\"\"\n",
    "        Calculate cross-entropy loss\n",
    "        The loss increases as the predicted probability diverge from the actual label.\n",
    "\n",
    "        Parameters:\n",
    "        yG:\n",
    "        y:\n",
    "\n",
    "        Returns:\n",
    "        loss: Average cross entropy loss\n",
    "        \"\"\"\n",
    "\n",
    "        # Y must be one-hot encoded\n",
    "        rows = yG.shape[0]\n",
    "        loss =- np.sum(y * np.log(yG))\n",
    "\n",
    "    return loss/float(rows)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML = MultiLogisticReg()\n",
    "\n",
    "ML.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(self, X):\n",
    "    decision_threshold = 0.5\n",
    "\n",
    "    x_b = np.c_[np.ones((np.shape(X)[0],1)),X]\n",
    "    z = np.dot(x_b, self.weights)\n",
    "\n",
    "    predictions = []\n",
    "    for i in self.sigmoid(z):\n",
    "        if i > decision_threshold:\n",
    "            predictions.append(1)\n",
    "        else:\n",
    "            predictions.append(0)\n",
    "            \n",
    "    return predictions\n",
    "\n",
    "def predictProba(self, X):\n",
    "    x_b = np.c_[np.ones((np.shape(X)[0],1)),X]\n",
    "    z = np.dot(x_b, self.weights)\n",
    "    probs = self.sigmoid(z)\n",
    "\n",
    "    return probs\n",
    "\n",
    "def lossFunction(probs, target):\n",
    "    \"\"\"\n",
    "    Calculates cross entropy loss for a set of predictions and actual targets.\n",
    "    Cross-entropy is a measure of the difference between two probability distributions for a given random variable\n",
    "\n",
    "    Parameters:\n",
    "    probs: Probability predictions in MultiLogisticReg\n",
    "    target: Actual target values\n",
    "\n",
    "    Returns:\n",
    "    loss: Average cross entropy loss\n",
    "    \"\"\"\n",
    "\n",
    "    rows = probs.shape[0]\n",
    "    loss = 0\n",
    "\n",
    "    for row, i in zip(probs, target):\n",
    "        loss += -np.log(row[i])\n",
    "    loss /= rows\n",
    "    return loss\n",
    "\n",
    "def gradientDescent(self, rounds, weight, alpha):\n",
    "\n",
    "    for i in range(rounds):\n",
    "        z = np.dot(self.X, weight)\n",
    "        print(z)\n",
    "        sigm = self.sigmoidFunc(z)\n",
    "        sigm -= np.reshape(self.y,(len(self.y), 1))\n",
    "\n",
    "        gradient = np.dot(self.X.T, sigm)\n",
    "        \n",
    "        weight = weight - alpha * gradient\n",
    "        # cost value\n",
    "        self.h[i] = self.lossFunction(weight)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "34f0680f93e83a4a101ea3928db54ef43df704f0ed6210e5ae2b09f0ef086431"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
